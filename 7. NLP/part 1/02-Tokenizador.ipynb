{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taller 2 Tokenización y segmentación PLN\n",
    "\n",
    "*El proceso de tokenización es la tarea de segmentar en palabras el texto en ejecución.*\n",
    "\n",
    "*Esta práctica trata sobre el preprocesamiento básico de texto, con las herramientas disponibles para el idioma español y vistas en clase. Para el desarrollo de esta práctica, se utilizó el conjunto de datos almacenados en el directorio DataSet, consta de 10 Archivos de texto de diferentes tamaños.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: Se instala la librería nltk.\n",
    "*La librería Natural language toolkit (NLTK) es una bilbioteca o librería muy popular para el procesamiento de lenguaje natural escrita en Python.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Se importa la librería nltk para realizar el proceso de tokenización.\n",
    "*Para iniciar a trabajar con nltk se descarga lo que se denomina el corpora NLTK. Se teclea lo siguiente: nltk.download() después de la librería, se obtiene un GUI desde el que se descarga los paquetes necesarios.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Se importa la librería os y se usa el método listdir para listar los archivos del DataSet.\n",
    "*La librería o biblioteca os, permite acceder a diferentes funcionalidades y dependencias del Sistema Operativo, sobre todo aquellas que corresponden al entorno y manipulación de estructura de directorios.*\n",
    "\n",
    "*El método de Python listdir() devuelve una lista que contiene los nombres de las entradas en el directorio dado por la ruta.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text10.txt',\n",
       " 'text2.txt',\n",
       " 'text3.txt',\n",
       " 'text4.txt',\n",
       " 'text5.txt',\n",
       " 'text6.txt',\n",
       " 'text7.txt',\n",
       " 'text8.txt',\n",
       " 'text9.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "contenido = os.listdir('DataSet/')\n",
    "contenido"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Se leen los archivos que se encuentran dentro del DataSet y se almacenan en vector, finalmente, el vector se pasa al DataFrame vectorpd.\n",
    "*Se usa open para comenzar a leer un arhivo en Python, incluyendo el argumento 'r' que significa modo lectura. En este caso, se usa para leer los archivos listados anteriormente*\n",
    "*Enseguida, se almacena todo el contenido de los archivos en un vector para preprocesar el contenido en un DataFrame.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0\n",
      "0   <doc id=\"2218136\" title=\"Vedad Ibi¨evi?\" nonfi...\n",
      "1                                                  \\n\n",
      "2                                                  \\n\n",
      "3   Vedad Ibi¨evi , nacido el 6 de agosto de 1984 ...\n",
      "4                                                  \\n\n",
      "5                                     Trayectoria .\\n\n",
      "6                                                  \\n\n",
      "7   Como consecuencia de la Guerra de Bosnia, su f...\n",
      "8                                                  \\n\n",
      "9   Durante su estancia en Estados Unidos fue ojea...\n",
      "10                                                 \\n\n",
      "11  En mayo de 2006, firmó por 3 años con el Alema...\n",
      "12                                                 \\n\n",
      "13  Comenzó de forma fulgurante la campaña 2008-20...\n",
      "14                                                 \\n\n",
      "15                                                 \\n\n",
      "16                                                 \\n\n",
      "17                                                 \\n\n",
      "18                                                 \\n\n",
      "19                                      Selección .\\n\n",
      "20                                                 \\n\n",
      "21  Debutó con la selección de Bosnia-Herzegovina ...\n",
      "22                                                 \\n\n",
      "23  Desde entonces ha participado en encuentros de...\n",
      "24                                                 \\n\n",
      "25                                          Notas .\\n\n",
      "26                                                 \\n\n",
      "27                                                 \\n\n",
      "28                               Enlaces externos .\\n\n",
      "29                                                 \\n\n",
      "30             Official Website. (bosnio e inglés);\\n\n",
      "31    Perfil en la página del Hoffenheim. (alemán);\\n\n",
      "32  Perfil en national-football-teams.com (inglés);\\n\n",
      "33                                                 \\n\n",
      "34                                                 \\n\n",
      "35                                                 \\n\n",
      "36                                                 \\n\n",
      "37                                                 \\n\n",
      "38                                                 \\n\n",
      "39                                                 \\n\n",
      "40                                                 \\n\n",
      "41                                                 \\n\n",
      "42                                                 \\n\n",
      "43                                                 \\n\n",
      "44                                                 \\n\n",
      "45                                                 \\n\n",
      "46                                                 \\n\n",
      "47                                                 \\n\n",
      "48                                                 \\n\n",
      "49                                                 \\n\n"
     ]
    }
   ],
   "source": [
    "#Se importan las librerías numpy y pandas para cargar el vector a un DataFrame.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Se define el ciclo para recorrer cada uno de los archivos que se encuentran dentro de DataSet.\n",
    "for archivo in contenido:\n",
    "    #Se lee cada uno de los archivos de DataSet urilizando el encoding ISO-8859-1.\n",
    "    with open('DataSet/'+archivo,'r',encoding='ISO-8859-1') as fname:\n",
    "        #El contenido de cada archivo leído, se almacena en vector.\n",
    "        vector_df = pd.DataFrame(fname.readlines())\n",
    "#Se imprimen las 50 primeras líneas del vector.\n",
    "print(vector_df[:50])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5: Se hace el preprocesamiento del DataFrame vectorpd.\n",
    "*El preprocesamiento consiste en organizar y limpiar los datos que se encuentran almacenados en el DataFrame y que se usarán en el proceso de tokenización. Para este caso, se eliminaron los saltos de línea '\\n', las etiquetas que inician con '<' y la palabra reservada 'ENDOFARTICLE', que se encuetran dentro de los archivos a procesar.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vedad Ibi¨evi , nacido el 6 de agosto de 1984 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trayectoria .\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Como consecuencia de la Guerra de Bosnia, su f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Durante su estancia en Estados Unidos fue ojea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>En mayo de 2006, firmó por 3 años con el Alema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124069</th>\n",
       "      <td>Aranguren;\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124070</th>\n",
       "      <td>Cuenca de Pamplona;\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124071</th>\n",
       "      <td>Navarra;\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124072</th>\n",
       "      <td>Enlaces externos.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124073</th>\n",
       "      <td>Mutilva Alta - Enciclopedia Auñamendi;\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56447 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "3       Vedad Ibi¨evi , nacido el 6 de agosto de 1984 ...\n",
       "5                                         Trayectoria .\\n\n",
       "7       Como consecuencia de la Guerra de Bosnia, su f...\n",
       "9       Durante su estancia en Estados Unidos fue ojea...\n",
       "11      En mayo de 2006, firmó por 3 años con el Alema...\n",
       "...                                                   ...\n",
       "124069                                       Aranguren;\\n\n",
       "124070                              Cuenca de Pamplona;\\n\n",
       "124071                                         Navarra;\\n\n",
       "124072                                Enlaces externos.\\n\n",
       "124073           Mutilva Alta - Enciclopedia Auñamendi;\\n\n",
       "\n",
       "[56447 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se reemplaza el \\n con NaN y se eliminan del DataFrame.\n",
    "vector_df = vector_df.replace(\"\\n\", np.NaN).dropna()\n",
    "#Se busca en el DataFrame las filas que contienen '<' y se eliminan.\n",
    "#vector_df = vector_df[~vector_df.stack().str.contains('<').any(level=0)]\n",
    "vector_df = vector_df[~vector_df.apply(lambda row: row.astype(str).str.contains('<')).any(axis=1)]\n",
    "#Se busca en el DataFrame las filas que contienen 'ENDOFARTICLE.' y se eliminan.\n",
    "#vector_df = vector_df[~vector_df.stack().str.contains('ENDOFARTICLE.').any(level=0)]\n",
    "vector_df = vector_df[~vector_df.apply(lambda row: row.astype(str).str.contains('ENDOFARTICLE.')).any(axis=1)]\n",
    "#Se imprime el vectorpd para verificar el contenido del DataFrame.\n",
    "vector_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 6: Se importa la librería nltk y el word_tokenize para tokenizar por palabras el DataFrame. Finalmente, las palabras que se tokenizaron se almacenan en el vectorpalabras.\n",
    "*Para realizar el proceso de tokenización se utilizó el método word-tokenize de la librería nltk, que recibe como parámetro de entrada el DataFrame ya preprocesado y posteriormente, se covierte a un vector de palabras que contiene la tokenización de los archivos del DataSet.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Vedad', 'Ibi¨evi', ',', 'nacido', 'el', '6', 'de', 'agosto', 'de', '1984', 'en', 'Vlasenica', ',', 'Yugoslavia', '(', 'actual', 'Bosnia', 'y', 'Herzegovina', ')', 'es', 'un', 'futbolista', 'bosnio', 'que', 'juega', 'como', 'delantero', 'en', 'el', 'TSG', '1899', 'Hoffenheim', 'de', 'la', 'Bundesliga', 'de', 'Alemania', '.'], ['Trayectoria', '.'], ['Como', 'consecuencia', 'de', 'la', 'Guerra', 'de', 'Bosnia', ',', 'su', 'familia', 'debió', 'abandonar', 'Vlasenica', ',', 'que', 'cayó', 'en', 'manos', 'serbias', ',', 'y', 'fue', 'desplazada', 'a', 'Tuzla', ',', 'donde', 'Vedad', 'comenzó', 'a', 'jugar', 'al', 'fútbol', '.', 'Ibi¨evi', 'y', 'su', 'familia', 'abandonaron', 'Bosnia', 'y', 'Herzegovina', 'en', '2000', ',', 'para', 'trasladarse', 'a', 'Suiza', ',', 'donde', 'jugó', 'como', 'juvenil', 'en', 'el', 'FC', 'Basilea', '1893', '.', 'Sin', 'embargo', ',', 'su', 'familia', 'abandonó', 'Suiza', 'después', 'de', 'sólo', 'diez', 'meses', ',', 'para', 'trasladarse', 'a', 'San', 'Luis', ',', 'en', 'los', 'Estados', 'Unidos', '.', 'Allí', 'jugó', 'con', 'el', 'equipo', 'de', 'la', 'Universidad', 'de', 'San', 'Luis', ',', 'una', 'de', 'las', 'instituciones', 'más', 'respetadas', 'del', 'fútbol', 'en', 'el', 'país', '.', 'Por', 'sus', 'logros', ',', 'fue', 'nombrado', 'debutante', 'del', 'año', 'en', 'la', 'NCAA', '.'], ['Durante', 'su', 'estancia', 'en', 'Estados', 'Unidos', 'fue', 'ojeado', 'por', 'el', 'Paris', 'Saint-Germain', ',', 'de', 'la', 'Ligue', '1', 'de', 'Francia', ',', 'que', 'lo', 'fichó', 'en', '2004', '.', 'Al', 'disponer', 'de', 'pocos', 'minutos', 'de', 'juego', 'se', 'incorporó', 'en', '2005', 'al', 'Dijon', 'FCO', ',', 'de', 'la', 'Ligue', '2', ',', 'donde', 'marcó', '10', 'goles', 'en', 'una', 'temporada', '.'], ['En', 'mayo', 'de', '2006', ',', 'firmó', 'por', '3', 'años', 'con', 'el', 'Alemannia', 'Aachen', 'de', 'la', 'Bundesliga', ',', 'y', 'el', '12', 'de', 'julio', 'de', '2007', 'se', 'incorporó', 'a', 'otro', 'club', 'alemán', ',', 'el', 'TSG', '1899', 'Hoffenheim', '.'], ['Comenzó', 'de', 'forma', 'fulgurante', 'la', 'campaña', '2008-2009', ',', 'habiendo', 'conseguido', '18', 'goles', 'en', 'las', 'primeras', '16', 'jornadas', 'de', 'campeonato', '.'], ['Selección', '.'], ['Debutó', 'con', 'la', 'selección', 'de', 'Bosnia-Herzegovina', 'el', '24', 'de', 'marzo', 'de', '2007', ',', 'jugando', 'como', 'titular', 'ante', 'Noruega', 'en', 'encuentro', 'de', 'clasificación', 'para', 'la', 'Eurocopa', '2008', ',', 'y', 'marcó', 'su', 'primer', 'gol', 'el', '13', 'de', 'octubre', 'de', '2007', 'en', 'Atenas', 'ante', 'Grecia', ',', 'también', 'en', 'encuentro', 'clasificatorio', 'para', 'la', 'Eurocopa', '.'], ['Desde', 'entonces', 'ha', 'participado', 'en', 'encuentros', 'de', 'clasificación', 'para', 'la', 'Copa', 'Mundial', 'de', 'Fútbol', 'de', '2010', '.'], ['Notas', '.'], ['Enlaces', 'externos', '.'], ['Official', 'Website', '.', '(', 'bosnio', 'e', 'inglés', ')', ';'], ['Perfil', 'en', 'la', 'página', 'del', 'Hoffenheim', '.', '(', 'alemán', ')', ';'], ['Perfil', 'en', 'national-football-teams.com', '(', 'inglés', ')', ';'], ['Bernie', 'Paz', '(', 'n.', 'en', '1968', ',', 'Lima', ',', 'Perú', ')', 'actor', 'peruano', 'de', 'telenovelas', '.', 'Actualmente', 'radica', 'en', 'Miami', '.'], ['Televisión', '.'], ['Amor', 'Serrano', '(', '1998', ')', ';'], ['María', 'Rosa', ',', 'búscame', 'una', 'esposa', '(', '2000', ')', '....', 'Gonzalo', ';'], ['Vidas', 'prestadas', '(', '2000', ')', '....', 'Renato', \"'Reni\", \"'\", 'Valente', 'López', ';'], ['Soledad', '(', '2001', ')', '....', 'Leonardo', \"'Leo\", \"'\", 'García', ';'], ['Todo', 'sobre', 'Camila', '(', '2003', ')', '....', 'Eduardo', 'Bonfil', ';'], ['Ángel', 'rebelde', '(', '2004', ')', '....', 'Claudio', 'Salazar', ';'], ['Milagros', '(', '2005', ')', '....', 'Gringo', 'Veloachaga', ';'], ['El', 'Pasado', 'no', 'perdona', '(', '2005', ')', '....', 'Esteban', 'Zaldivar/Manuel', 'Lara', ';'], ['Tierra', 'de', 'pasiones', '(', '2006', ')', '....', 'Fernando', 'Solís', ';'], ['Decisiones', '(', '1', 'episodio', ',', '2007', ')', '....', 'Manuel', ';'], ['Acorralada', '(', '2007', ')', '....', 'Rodrigo', ';'], ['Mi', 'adorada', 'Malena', '(', '2007', ')', '....', 'Leonardo', ';'], ['Amas', 'de', 'casa', 'desesperadas', '(', '2008', ')', '....', 'Carlos', 'Solis', ';'], ['Condesa', 'por', 'amor', '(', '2009', ')', '....', 'Anibal', ';'], ['Cine', '.'], ['El', 'Destino', 'no', 'tiene', 'favoritos', '(', '2003', ')', '....', 'Alejandro', ';'], ['Referencias', '.'], ['Enlaces', 'externos', '.'], ['Thibault', 'Damour', 'es', 'un', 'físico', 'francés', 'nacido', 'en', '1951', '.'], ['Es', 'profesor', 'de', 'física', 'teórica', 'en', 'el', 'Institut', 'des', 'hautes', 'études', 'scientifiques', '(', 'IHES', ')', 'desde', '1989', '.', 'Experto', 'en', 'la', 'relatividad', 'general', ',', 'ha', 'enseñado', 'esta', 'teoría', 'por', 'mucho', 'tiempo', 'en', 'la', 'Escuela', 'Normal', 'Superior', 'de', 'París', '(', 'Ulm', ')', '.', 'También', 'es', 'especialista', 'en', 'la', 'teoría', 'de', 'cuerdas', '.'], ['Enlaces', 'externos', '.'], ['Página', 'de', 'Damour', 'en', 'el', 'IHES', ';'], ['El', 'término', 'El', 'columpio', 'puede', 'referirse', 'a', ':'], ['Columpio', ',', 'diversión', 'infantil', ';'], ['El', 'columpio', ',', 'cartón', 'para', 'tapiz', 'de', 'Francisco', 'de', 'Goya', ';'], ['El', 'columpio', ',', 'cuadro', 'de', 'Fragonard', ';'], ['Magdalena', 'Ko¸ená', ',', 'nacida', 'en', 'Brno', 'en', 'Checoslovaquia', 'en', '1973', 'es', 'una', 'de', 'las', 'más', 'destacadas', 'mezzosoprano', 'actuales', 'cuyo', 'timbre', 'eslavo', 'recuerda', 'a', 'la', 'gran', 'soprano', 'eslovaca', 'Lucia', 'Popp', '.'], ['Estudió', 'canto', 'y', 'piano', 'en', 'el', 'Conservatorio', 'de', 'Brno', 'y', 'con', 'Eva', 'Blahova', 'en', 'Bratislava', '.', 'En', '1995', 'ganó', 'el', 'VII', 'Concurso', 'Mozart', 'en', 'Salzburgo', ',', 'debutando', 'como', 'Dorabella', 'y', 'Annio', 'en', 'la', 'Volksoper', 'de', 'Viena', '.'], ['Considerada', 'soberbia', 'cantante', 'en', 'la', 'música', 'del', 'barroco', ',', 'Bach', ',', 'Handel', ',', 'Mozart', '-', 'Idamante', ',', 'Cherubino', ',', 'Sesto', ',', 'Dorabella-', ',', 'Debussy', ',', 'Britten', ',', 'Ravel', ',', 'Respighi', ',', 'Schulhoff', ',', 'Shostakovich', ',', 'y', 'Janá', 'ek', 'ha', 'grabado', 'con', 'Gardiner', ',', 'Harnoncourt', ',', 'Minkowski', ',', 'Chung', ',', 'Rattle', 'y', 'otros', 'presentándose', 'en', 'todas', 'las', 'grandes', 'casa', 'líricas', 'y', 'festivales', ':', 'Edimburgo', ',', 'Salzburgo', ',', 'Munich', ',', 'Roma', ',', 'New', 'York', ',', 'etc', '.'], ['Es', 'Chevalier', 'de', \"l'Ordre\", 'des', 'Arts', 'et', 'des', 'Lettres', 'por', 'el', 'Gobierno', 'Francés', '(', '2003', ')', 'y', 'Artista', 'del', 'Año', '2004', 'de', 'la', 'prestigiosa', 'revista', 'Gramophone', '.'], ['Como', 'liederista', 'trabaja', 'con', 'Graham', 'Johnson', 'y', 'Malcolm', 'Martineau', 'actuando', 'en', 'Londres', '(', 'Wigmore', 'Hall', ')', ',', 'París', ',', 'Viena', '(', 'Konzerthaus', ')', ',', 'Nueva', 'York', '(', 'Carnegie', 'Hall', ')', ',', 'Amsterdam', '(', 'Concertgebouw', ')', ',', 'Festival', 'de', 'Música', 'Antigua', 'de', 'Utrecht', ',', 'Barbican', 'de', 'Londres', ',', 'Lincoln', 'Center', 'de', 'Nueva', 'York', ',', 'Festivales', 'de', 'Verbier', ',', 'Schleswig-Holstein', 'y', 'en', 'los', 'Proms', 'londinenses', '.'], ['Estuvo', 'casada', 'con', 'el', 'barítono', 'Vincent', 'le', 'Texier', ';', 'actualmente', 'vive', 'con', 'el', 'director', 'Sir', 'Simon', 'Rattle', 'con', 'quien', 'tuvo', 'su', 'hijo', 'Jonas', 'en', 'el', 'año', '2005', '.'], ['Discografía', 'de', 'referencia', '.'], ['Ah', '!', 'Mio', 'Cor', '-', 'Handel', 'Arias', '/', 'Marcon', ';']]\n"
     ]
    }
   ],
   "source": [
    "#Se importa la librería nltk para tokenizar las palabras.\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#Se define el vector donde quedan almacenadas las palabras tokenizadas.\n",
    "vectorpalabras = []\n",
    "\n",
    "#Se hace el proceso de tokenizado para el DataFrame y se adiciona el contenido al vectorpalabras.\n",
    "vectorpalabras.append(vector_df.apply(lambda row: nltk.word_tokenize(row[0]), axis=1))\n",
    "#Se convierte el DataFrame vectorpalabras a la lista vectorpalabras.\n",
    "vectorpalabras=vectorpalabras[0].tolist()\n",
    "#Se imprime la lista vectorpalabras.\n",
    "#print(vectorpalabras)\n",
    "print(vectorpalabras[:50])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
